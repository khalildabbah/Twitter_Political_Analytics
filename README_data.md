## Data Collection Layer for Twitter/X Political Analytics Dashboard

This directory describes the **offline Python data collection pipeline** that feeds
the Next.js dashboard. The dashboard UI is not touched by this script – it only
writes JSON/CSV files under `data/` at the project root.

### 1. Python environment setup

From the project root (`Twitter_Political_Analytics/`), create and activate a
virtual environment.

On **Windows (PowerShell)**:

```bash
python -m venv .venv
.venv\Scripts\Activate.ps1
```

On **macOS / Linux**:

```bash
python -m venv .venv
source .venv/bin/activate
```

Upgrade `pip` (recommended):

```bash
python -m pip install --upgrade pip
```

### 2. Install dependencies

Inside the virtualenv, install the required Python packages:

```bash
pip install snscrape pandas
```

> Note: `snscrape` is a Python library for scraping Twitter/X and other social
> networks without using the official API.

### 3. Running the scraper

From the project root, run:

```bash
python backend/scraping/scrape_tweets.py
```

What this script does:

- Ensures a `data/` directory exists at the project root (and a `data/raw//`
  subfolder for future extensions).
- Scrapes recent tweets (up to a per-account cap and 30 days back) from the
  accounts listed in the `ACCOUNTS` list inside
  `backend/scraping/scrape_tweets.py`.
- Collects per-tweet fields such as:
  - tweet id, URL, username, display name
  - group (Hadash-Ta'al, Ra'am, Islamic/Independent, Activist)
  - human-readable label
  - full text, language, creation datetime (ISO string)
  - like / retweet / reply / quote counts
  - computed `virality_score = likes + retweets + replies + quotes`
- Writes two files:
  - `data/all_tweets.csv`
  - `data/all_tweets.json` (pretty-printed)

The script logs simple progress messages like:

```text
Scraping @AyOdeh (Hadash-Ta'al)...
Finished @AyOdeh (Hadash-Ta'al) — collected XXX tweets
```

Errors for individual accounts (e.g. TODO placeholders, suspended users) are
logged as warnings and **do not** stop the whole run.

### 4. How this connects to the dashboard

Right now, the Next.js dashboard uses mock data under `data/dashboard_summary.mock.json`.
In the future you can wire the frontend to read from `data/all_tweets.json`
generated by this Python layer (e.g. via a build-time script or simple API
route) to power:

- Cross-party comparisons
- Per-account analytics
- Virality / engagement leaderboards

The `backend/` folder is intentionally self-contained so you can iterate on the
Python analysis (using pandas, offline models, etc.) without changing the UI
code.

